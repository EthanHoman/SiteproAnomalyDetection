# Pump Anomaly Detection System - Mermaid Diagrams

This file contains the three main system diagrams in Mermaid format.

---

## 1. System Class Diagram

```mermaid
classDiagram
    %% Core Analysis System
    class PumpMonitor {
        -baseline: dict
        -tolerances: dict
        -operational_df: DataFrame
        -model: RandomForestRegressor
        +load_operational_data(filepath)
        +analyze()
        +generate_report()
        +get_current_status()
    }

    class DataProcessor {
        +load_baseline_data(filepath) dict
        +load_operational_data(filepath) DataFrame
        +calculate_deviations(df, baseline) DataFrame
        +validate_data(df)
    }

    class ToleranceChecker {
        -tolerances: dict
        +select_tolerance_category(app, hp) str
        +check_tolerances(deviations) dict
        +classify_status(violations) str
    }

    class PredictiveModel {
        -model: RandomForestRegressor
        -scaler: StandardScaler
        +engineer_features(df) DataFrame
        +train_failure_predictor(X, y) model
        +predict_failure(data) dict
    }

    class Visualizer {
        +plot_dashboard(df)
        +plot_timeline(events)
        +plot_trends(df)
    }

    %% Edge Deployment System
    class EdgeInference {
        -model: object
        -baseline: dict
        -tolerances: dict
        -api_client: AnomalyAPIClient
        -last_reported: dict
        +run_inference(input_csv, output_json)
        +calculate_deviations(row) dict
        +check_tolerances(deviations) dict
        +format_anomaly_payload(results) dict
        +should_report_anomaly() bool
    }

    class AnomalyAPIClient {
        -base_url: str
        -bearer_token: str
        +submit_anomaly(payload) dict
        +query_anomalies(filters) dict
    }

    class ArtifactPackager {
        -pump_name: str
        -version: str
        +load_baseline(file)
        +package(output_path)
    }

    %% Data Models
    class BaselineData {
        +well_id: str
        +baseline_flow_gpm: float
        +baseline_discharge_pressure_psi: float
        +baseline_power_hp: float
        +baseline_efficiency_percent: float
    }

    class AnomalyPayload {
        +sourceType: str
        +description: str
        +siteId: int
        +pumpId: int
        +timestamp: str
        +additionalContext: dict
        +metadata: dict
    }

    %% Relationships
    PumpMonitor --> DataProcessor : uses
    PumpMonitor --> ToleranceChecker : uses
    PumpMonitor --> PredictiveModel : uses
    PumpMonitor --> Visualizer : uses
    PumpMonitor ..> BaselineData : processes

    EdgeInference --> AnomalyAPIClient : uses
    EdgeInference ..> AnomalyPayload : creates

    ArtifactPackager ..> PredictiveModel : packages
    ArtifactPackager --> EdgeInference : creates artifact for

    note for PumpMonitor "Main orchestrator for\ntraining and analysis\n\nPhase 1: Core System"
    note for EdgeInference "Runs on edge device\n(Raspberry Pi)\n\nPhase 2B: Edge Deployment"
```

---

## 2. System Use Case Diagram

```mermaid
graph LR
    %% Actors
    analyst((Data Analyst))
    devops((DevOps Engineer))
    edge((Edge Device))
    api((Central API))

    %% Phase 1: Training & Analysis
    subgraph Phase1[Phase 1: Training & Analysis]
        UC1[UC1: Load Pump Data]
        UC2[UC2: Calculate Deviations]
        UC3[UC3: Check Tolerances]
        UC4[UC4: Train ML Model]
        UC5[UC5: Generate Report]
    end

    %% Phase 2B: Edge Deployment
    subgraph Phase2B[Phase 2B: Edge Deployment]
        UC6[UC6: Package Artifact]
        UC7[UC7: Deploy to Edge]
        UC8[UC8: Run Inference]
        UC9[UC9: Detect Anomaly]
        UC10[UC10: Send JSON to API]
    end

    %% Analyst workflows
    analyst --> UC1
    analyst --> UC2
    analyst --> UC3
    analyst --> UC5

    %% DevOps workflows
    devops --> UC4
    devops --> UC6
    devops --> UC7

    %% Edge device workflows
    edge --> UC8
    edge --> UC9

    %% API interactions
    UC10 -.->|POST JSON payload| api

    %% Workflow dependencies
    UC2 -.->|include| UC1
    UC3 -.->|include| UC2
    UC5 -.->|include| UC3
    UC5 -.->|extend| UC4

    UC7 -.->|include| UC6
    UC8 -.->|requires| UC7
    UC9 -.->|part of| UC8
    UC10 -.->|triggered by| UC9
```

---

## 3. System Sequence Diagram - Edge Inference to API

```mermaid
sequenceDiagram
    participant Cron as Cron Job<br/>(Hourly)
    participant Inference as EdgeInference
    participant Sensor as Sensor Data<br/>(CSV)
    participant Model as ML Model
    participant Client as AnomalyAPIClient
    participant API as Central API<br/>(Azure)
    participant Results as Results<br/>(JSON)

    Note over Cron,Results: Initialization (on startup)

    Cron->>Inference: EdgeInference(".")
    Inference->>Inference: load_model()
    Inference->>Inference: load_baseline()
    Inference->>Inference: load_tolerances()
    Inference->>Client: new AnomalyAPIClient(base_url, token)
    Client-->>Inference: ready

    Note over Cron,Results: Hourly Inference

    Cron->>Inference: run_inference("sensor_data.csv", "results.json")

    rect rgb(240, 248, 255)
        Note right of Inference: Read Sensor Data
        Inference->>Sensor: read CSV
        Note right of Sensor: timestamp, Flow (gpm),<br/>Discharge Pressure (psi),<br/>Motor Power (hp),<br/>Pump Efficiency (%)
        Sensor-->>Inference: DataFrame[3 rows]
        Inference->>Inference: select latest row
    end

    rect rgb(255, 250, 240)
        Note right of Inference: Calculate Deviations
        loop for each parameter
            Inference->>Inference: deviation = ((current - baseline) / baseline) × 100
        end
        Note right of Inference: deviations = {<br/>flow: 15.0, head: 10.0,<br/>power: 8.5, efficiency: -1.2}
    end

    rect rgb(240, 255, 240)
        Note right of Inference: Check Tolerances
        loop for each parameter
            Inference->>Inference: check if deviation > max_threshold
            Inference->>Inference: check if deviation < min_threshold
        end

        alt Flow or Head exceeded (mandatory params)
            Inference->>Inference: status = "Warning"
            Note right of Inference: violations = {flow: {...}, head: {...}}
        else Multiple violations or severe
            Inference->>Inference: status = "Critical" or "Failure"
        else No violations
            Inference->>Inference: status = "Normal"
        end
    end

    rect rgb(255, 240, 245)
        Note right of Inference: ML Prediction
        alt DataFrame has >= 168 rows
            Inference->>Inference: extract_features(df)
            Inference->>Model: predict(features)
            Model-->>Inference: rul_days = 12.5
            Inference->>Inference: probability = 0.85, confidence = 0.87
        else Not enough data
            Inference->>Inference: prediction = None
        end
    end

    rect rgb(245, 245, 250)
        Note right of Inference: Determine If Reporting Needed
        alt status == "Normal"
            Inference->>Inference: should_report = False
        else recently reported (< 60 min)
            Inference->>Inference: should_report = False (debounced)
        else mandatory exceeded OR critical status OR ML predicts failure
            Inference->>Inference: should_report = True
        end
    end

    rect rgb(255, 245, 230)
        Note over Inference,API: Send JSON Payload to API
        alt should_report == True
            Inference->>Inference: format_anomaly_payload()

            Note right of Inference: JSON Payload:<br/>{<br/>  "sourceType": "log",<br/>  "description": "Flow exceeded 15.0%",<br/>  "siteId": 35482,<br/>  "pumpId": 1,<br/>  "sensorId": 101,<br/>  "timestamp": "2024-11-19T14:32:00Z",<br/>  "logValue": 575.0,<br/>  "additionalContext": {<br/>    "status": "Warning",<br/>    "all_deviations": {...},<br/>    "baseline_values": {...},<br/>    "current_values": {...}<br/>  },<br/>  "metadata": {<br/>    "modelVersion": "1.0.0",<br/>    "confidence": 0.87,<br/>    "prediction_rul_days": 12.5<br/>  }<br/>}

            Inference->>Client: submit_anomaly(json_payload)

            rect rgb(250, 250, 255)
                Note right of Client: Retry Logic (3 attempts)
                loop attempt = 1 to 3
                    Client->>API: POST /edge/anomalies<br/>Authorization: Bearer TOKEN<br/>Content-Type: application/json<br/><br/>{JSON payload}

                    alt API Success (200 OK)
                        API-->>Client: {id: 12345, ...payload, createdAt: "..."}
                        Client-->>Inference: success
                        Inference->>Inference: update_debounce_tracker()
                        Note right of Inference: Won't report same<br/>parameter for 60 min
                    else API Error
                        API-->>Client: error
                        alt attempt < 3
                            Client->>Client: wait (exponential backoff)
                        else all retries failed
                            Client-->>Inference: error
                            Inference->>Inference: save_unsent_anomaly(payload)
                            Note right of Inference: Save locally<br/>for retry later
                        end
                    end
                end
            end
        end
    end

    rect rgb(240, 255, 255)
        Note right of Inference: Save Results Locally
        Inference->>Inference: compile_results()
        Note right of Inference: {<br/>  "timestamp": "2024-11-19T14:32:00",<br/>  "status": "Warning",<br/>  "deviations": {...},<br/>  "violations": {...},<br/>  "prediction": {...},<br/>  "reported_to_api": true<br/>}
        Inference->>Results: write JSON file
        Results-->>Inference: saved
    end

    Inference-->>Cron: ✓ Inference complete<br/>Status: Warning<br/>Reported to API: Yes
```

---

## Key Features Highlighted in These Diagrams

### Class Diagram
- **Core Analysis System**: PumpMonitor orchestrates data processing, tolerance checking, ML predictions, and visualization
- **Edge Deployment System**: EdgeInference handles real-time monitoring on Raspberry Pi with API reporting
- **Data Models**: BaselineData and AnomalyPayload define the data structures

### Use Case Diagram
- **Phase 1 Workflows**: Data loading → Deviation calculation → Tolerance checking → ML training → Report generation
- **Phase 2B Workflows**: Artifact packaging → Edge deployment → Real-time inference → Anomaly detection → API reporting
- **Actors**: Data Analyst, DevOps Engineer, Edge Device, Central API

### Sequence Diagram
- **Complete edge inference flow**: From cron job initialization to API submission
- **Deviation calculation**: Compare sensor readings against baseline values
- **Tolerance checking**: Apply category 1U thresholds (Flow +10%, Head +6%, Power +10%, Efficiency -0%)
- **ML prediction**: Predict remaining useful life (RUL) and failure probability
- **Debouncing**: Prevent duplicate reports within 60 minutes
- **Retry logic**: Exponential backoff with 3 attempts (5s, 10s, 20s delays)
- **Graceful degradation**: Save locally if API unavailable
- **JSON payload**: Complete structure sent to POST /edge/anomalies endpoint

---

## Notes

- **Mermaid rendering**: These diagrams can be rendered in GitHub README.md, GitLab, Notion, or any Mermaid-compatible viewer
- **Real-time collaboration**: Mermaid diagrams are text-based, making them easy to version control and collaborate on
- **Dynamic updates**: Edit the diagram code directly to update the visualization
- **Export options**: Can be exported to PNG, SVG, or PDF using Mermaid CLI or online tools

---

**Created**: November 19, 2025
**Format**: Mermaid v10+
**Source**: Converted from PlantUML FINAL_DIAGRAMS.puml
